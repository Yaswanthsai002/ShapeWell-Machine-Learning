{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3877225",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2,time\n",
    "import math\n",
    "import mediapipe as mp\n",
    "import pyautogui\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "model=pickle.load(open('model.pkl','rb'))\n",
    "\n",
    "# Initializing mediapipe pose class.\n",
    "mp_holistic = mp.solutions.holistic\n",
    "\n",
    "# Initializing mediapipe drawing class, useful for annotation.\n",
    "mp_drawing = mp.solutions.drawing_utils \n",
    "\n",
    "def detectPose(image, pose, display=True):\n",
    "    '''\n",
    "    This function performs pose detection on an image.\n",
    "    Args:\n",
    "        image: The input image with a prominent person whose pose landmarks needs to be detected.\n",
    "        pose: The pose setup function required to perform the pose detection.\n",
    "        display: A boolean value that is if set to true the function displays the original input image, the resultant image, \n",
    "                 and the pose landmarks in 3D plot and returns nothing.\n",
    "    Returns:\n",
    "        output_image: The input image with the detected pose landmarks drawn.\n",
    "        landmarks: A list of detected landmarks converted into their original scale.\n",
    "    '''\n",
    "    \n",
    "    # Create a copy of the input image.\n",
    "    output_image = image.copy()\n",
    "    \n",
    "    # Convert the image from BGR into RGB format.\n",
    "    imageRGB = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # To improve performance, optionally mark the image as not writeable to pass by reference.\n",
    "    image.flags.writeable = False\n",
    "    \n",
    "    # Perform the Pose Detection.\n",
    "    results = pose.process(imageRGB)\n",
    "    \n",
    "    # Draw the pose annotation on the image.\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    \n",
    "    # Check if any landmarks are detected.\n",
    "    if results.pose_landmarks :\n",
    "        \n",
    "        # Draw Pose landmarks on the output image.        \n",
    "        # 1. Draw face landmarks\n",
    "        '''mp_drawing.draw_landmarks(output_image, results.face_landmarks, mp_holistic.FACEMESH_CONTOURS, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
    "                                 )\n",
    "        \n",
    "        # 2. Right hand\n",
    "        mp_drawing.draw_landmarks(output_image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 3. Left Hand\n",
    "        mp_drawing.draw_landmarks(output_image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "\n",
    "        # 4. Pose Detections\n",
    "        mp_drawing.draw_landmarks(output_image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "                                 mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4),\n",
    "                                 mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                                 )'''\n",
    "        \n",
    "    # Return the output image and the found landmarks.\n",
    "    return output_image, results\n",
    "\n",
    "# Pose Estimation\n",
    "\n",
    "# Setup Holistic Pose function for video.\n",
    "pose_video = mp_holistic.Holistic(static_image_mode=False, min_detection_confidence=0.5, model_complexity=2)\n",
    "\n",
    "screen_width, screen_height = pyautogui.size()\n",
    "\n",
    "# Initialize the VideoCapture object to read from the webcam.\n",
    "camera_video = cv2.VideoCapture(0)\n",
    "camera_video.set(3,1280)\n",
    "camera_video.set(4,960)\n",
    "\n",
    "# Initialize a resizable window.\n",
    "cv2.namedWindow('Pose Classification', cv2.WINDOW_NORMAL)\n",
    "\n",
    "fps = []\n",
    "\n",
    "# Initialize a variable to store the time of the previous frame.\n",
    "time1 = 0\n",
    "\n",
    "# Iterate until the webcam is accessed successfully.\n",
    "while camera_video.isOpened():\n",
    "\n",
    "    # Read a frame.\n",
    "    ok, frame = camera_video.read()\n",
    "\n",
    "    # Check if frame is not read properly.\n",
    "    if not ok:\n",
    "\n",
    "        # Continue to the next iteration to read the next frame and ignore the empty camera frame.\n",
    "        continue\n",
    "\n",
    "    # Flip the frame horizontally for natural (selfie-view) visualization.\n",
    "    frame = cv2.flip(frame, 1)\n",
    "\n",
    "    # Resize the frame while keeping the aspect ratio.\n",
    "    frame = cv2.resize(frame, (screen_width,screen_height))\n",
    "\n",
    "    # Perform Pose landmark detection.\n",
    "    frame, results = detectPose(frame,pose_video ,display=False)\n",
    "\n",
    "    # Check if the landmarks are detected.\n",
    "    if results.pose_landmarks:\n",
    "            row = list(np.array([[landmark.x, landmark.y, landmark.z] for landmark in results.pose_landmarks.landmark]).flatten())\n",
    "            X = pd.DataFrame([row])\n",
    "            body_language_class = model.predict(X)[0]\n",
    "            body_language_prob = model.predict_proba(X)[0]\n",
    "            #print(body_language_class,round(body_language_prob[np.argmax(body_language_prob)],2)*100)\n",
    "            if round(body_language_prob[np.argmax(body_language_prob)],2)*100 >= 70 :\n",
    "                cv2.putText(frame, str(\"Success: \",body_language_class), (300, 100),cv2.FONT_HERSHEY_PLAIN, 2, (0, 255, 0), 3)\n",
    "                # 2. Right hand\n",
    "                '''mp_drawing.draw_landmarks(frame, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                         mp_drawing.DrawingSpec(color=(255,255,255), thickness=2, circle_radius=4),\n",
    "                                         mp_drawing.DrawingSpec(color=(0,255,0), thickness=2, circle_radius=2)\n",
    "                                         )\n",
    "\n",
    "                # 3. Left Hand\n",
    "                mp_drawing.draw_landmarks(frame, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                         mp_drawing.DrawingSpec(color=(255,255,255), thickness=2, circle_radius=4),\n",
    "                                         mp_drawing.DrawingSpec(color=(0,255,0), thickness=2, circle_radius=2)\n",
    "                                         )'''\n",
    "\n",
    "                # 4. Pose Detections\n",
    "                mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "                                         mp_drawing.DrawingSpec(color=(255,255,255), thickness=2, circle_radius=4),\n",
    "                                         mp_drawing.DrawingSpec(color=(0,255,0), thickness=2, circle_radius=2)\n",
    "                                         )\n",
    "            else:\n",
    "                cv2.putText(frame, str(\"Unknown Pose\"), (300, 100),cv2.FONT_HERSHEY_PLAIN, 5, (0, 0, 255), 3)\n",
    "                cv2.putText(frame, '{} {}'.format(body_language_class,int(round(body_language_prob[np.argmax(body_language_prob)],2)*100)), (1500, 100),cv2.FONT_HERSHEY_PLAIN, 5, (0, 0, 255), 3)\n",
    "                # 2. Right hand\n",
    "                '''mp_drawing.draw_landmarks(frame, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                         mp_drawing.DrawingSpec(color=(255,255,255), thickness=2, circle_radius=4),\n",
    "                                         mp_drawing.DrawingSpec(color=(0,0,255), thickness=2, circle_radius=2)\n",
    "                                         )\n",
    "\n",
    "                # 3. Left Hand\n",
    "                mp_drawing.draw_landmarks(frame, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
    "                                         mp_drawing.DrawingSpec(color=(255,255,255), thickness=2, circle_radius=4),\n",
    "                                         mp_drawing.DrawingSpec(color=(0,0,255), thickness=2, circle_radius=2)\n",
    "                                         )'''\n",
    "\n",
    "                # 4. Pose Detections\n",
    "                mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS, \n",
    "                                         mp_drawing.DrawingSpec(color=(255,255,255), thickness=2, circle_radius=4),\n",
    "                                         mp_drawing.DrawingSpec(color=(0,0,255), thickness=2, circle_radius=2)\n",
    "                                         )\n",
    "\n",
    "    # Set the time for this frame to the current time.\n",
    "    time2 = time.time()\n",
    "\n",
    "    # Check if the difference between the previous and this frame time > 0 to avoid division by zero.\n",
    "    if (time2 - time1) > 0:\n",
    "\n",
    "        # Calculate the number of frames per second.\n",
    "        frames_per_second = 1.0 / (time2 - time1)\n",
    "\n",
    "        fps.append(int(frames_per_second))\n",
    "\n",
    "        # Write the calculated number of frames per second on the frame. \n",
    "        cv2.putText(frame, 'FPS: {}'.format(int(frames_per_second)), (0, 100),cv2.FONT_HERSHEY_PLAIN, 2, (0, 255, 0), 3)\n",
    "        \n",
    "        #Write the predicted asana label on the frame.\n",
    "        #cv2.putText(frame, str(body_language_class), (300, 100),cv2.FONT_HERSHEY_PLAIN, 2, (255, 0, 0), 3)\n",
    "        \n",
    "    # Update the previous frame time to this frame time.\n",
    "    # As this frame will become previous frame in next iteration.\n",
    "    time1 = time2\n",
    "\n",
    "    # Display the frame.\n",
    "    cv2.imshow('Pose Classification', frame)\n",
    "\n",
    "    # Wait until a key is pressed.\n",
    "    # Retreive the ASCII code of the key pressed\n",
    "    k = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    if(k==27):\n",
    "        break\n",
    "\n",
    "camera_video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d72b58f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goddess 43.0\n"
     ]
    }
   ],
   "source": [
    "print(body_language_class,round(body_language_prob[np.argmax(body_language_prob)],2)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b57994",
   "metadata": {},
   "outputs": [],
   "source": [
    "#camera_video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
